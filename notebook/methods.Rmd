---
title: "Methods"
author: "Christopher Tastad"
date: \today
bibliography: library.bib
output:
    html_document:
        toc: yes
#        toc_float: yes
        theme: paper
---

```{r echo=F}
library(knitr)
```

# Contacts

```{r echo=F}
contacts <- read.csv("/home/chris/starr_lab/contacts.csv")
kable(contacts)
```


# MSI

## Project Folder


The root project directory is:

* `/home/starrt2/`

I have a personal directory under the root. At the same level, there is also a shared directory which includes some content that is under active collaboration.

* `/home/starrt2/tasta005`

Processed data can be found in the hiseq folder under data_release. This data is mirrored in the msi file structure. Each file set is named by a unique ID which follows a naming convention given by umgc.

* Look for the leading 6 digit integer as a point of reference for the data_release folder.
* The Starr_Project sub folder is given a number which is considered the MSI and sample ID.

* `/home/starrt2/data_release/umgc/hiseq`

The Analysis directory contains the source data

* illumina-basicQC # quality control data
* cellranger-`*`
    + analysis # ?
    + filtered_gene_bc_matricies # data source that has been filtered by "true cell content"
    + raw_gene_bc_matrices # matrix data that includes unfiltered reads or all read content
    + web_summary.html # interactive cell ranger summary

An example of a complete data source location is below:

* `/home/starrt2/data_release/umgc/hiseq/170627_D00635_0259_ACB8R1ANXX/Starr_Project_037/Analysis/cellranger-Starr_037/filtered_gene_bc_matrices/GRCh38`

## New Cell Ranger Output

* It sounds like the Cell Ranger processing is a work in progress that is being conducted by Ying. They have 5 pt done, and the data is located at the root directory below.

* `/scratch.global/zhan2142/starr/`

## Load/Install R pkgs

* In order to run R in my MSI instance, I need to load the module and install applications.

```{r eval=F}
module load R/3.6.0
R
```

* To install packages in my local home directory, need to define a path.

```{r eval=F}
.libPaths(new='~/R/x86_64-pc-linux-gnu-library/3.6.0')
dir.create('~/R/x86_64-pc-linux-gnu-library/3.6.0', showWarnings = FALSE, recursive = TRUE)
```

* Confirm the path is correct.

```{r eval=F}
.libPaths()
```

* Choose as CRAN mirror.

```{r eval=F}
getCRANmirrors()
chooseCRANmirror(ind=2)
```

* Packages should be able to be installed and loaded normally now.

## MSI sshfs

#### Automount

I'm using `sshfs` to mount my MSI home folder on my local machine to make it more readily accessible. I already have ssh keys exchanged with MSI, so I can create an executable automount bash script. This is located at `/home/chris/starr_lab/auto_mnt_sshfs` on my local machine.

```{bash eval=F}
#!/bin/bash

sshfs tasta005@login.msi.umn.edu: ~/starr_lab/msi_mnt
```

#### Unmount

I've run into the case where a server disconnect causes a hang any time I navigate to this mount point. To reset the mount point use `fusermount` to force the unmount first.

```{r eval=F}
fusermount -uz /data
```


# Seurat

## PBMC Tutorial

```{r}
htmltools::includeHTML("../methods/code/seurat_tutorial/pbmc3k_tutorial.html")
```

# R

### Render .R -> .html

It is possible to render markdown output straight from a .R file. This can save the need to create two seperate files when running code and producing a formatted output.

https://rmarkdown.rstudio.com/articles_report_from_r_script.html

A markdown report can be compiled from an R script by:

```{r eval=F}
rmarkdown::render("analysis.R") # will generate an html output
rmarkdown::render("analysis.R", "pdf_document")
```

The metadata and output can be modified through special comments.

```{r eval=F}
#' ---
#' title: "Crop Analysis Q3 2013"
#' author: "John Smith"
#' date: "May 3rd, 2014"
#' output: pdf_document
#' ---
```

Additionally, regular markdown formatting can be applied behind this special comment type.

```{r eval=F}
#' A script comment that includes **markdown** formatting.
```


# CNV


## Varscan2

Tim wants me to try to use Varscan2 as a method to assess the exome data [@Koboldt2012]. Jinhua had tried this in some fashion previously.

#### from: Jinhua 6/14/19

If it is for single cell exome DNA copy number call, you may try this tool: SCOPE,   https://www.biorxiv.org/content/10.1101/594267v1.full

For low coverage whole exome CNV,  you may try: EXCAVATOR,  http://sourceforge.net/projects/excavatortool/,  and also VARscan 2.

## Contra

Juan had tried using contra in the past which did not work.

#### from: Juan 6/13/2019

Sure thing. In a nutshell back in 2013 I ran Contra with Tumor/Normal Samples and it worked, I got results... fast forward 6 years and the test files are not even working for me.


First, I attempted via Python 3, 2.7 and the original 2.6 version using the test set in my local computer. Then, I moved into the "Matrix" or in this case Mesabi.

With Help from Master Jedi Christy (Thank you Christy!) I created a conda environment for Contra via:

```{r eval=F}
conda create -n contra python=2.6
source activate /home/umgc-staff/abrah023/bin/miniconda3/envs/contra
```

change directory to folder containing Contra script (tried both Version 2.0.8 and 1.0.3).

```{r eval=F}

python contra.py --target ../0247401_D_BED_20090724_hg19_MERGED.bed --test ../P0667N_GATKrealigned_duplicates_marked.bam --control ../P0667T_GATKrealigned_duplicates_marked.bam --fasta human_g1k_v37.fasta --outfolder ../output2/
```

That was using the files that came with Contra and got an error:

```{r eval=F}


(contra) abrah023@ln0003 [~/AndyTemp/CONTRA.v2.0.8] % python contra.py --target ../0247401_D_BED_20090724_hg19_MERGED.bed --test ../P0667N_GATKrealigned_duplicates_marked.bam --control ../P0667T_GATKrealigned_duplicates_marked.bam --fasta human_g1k_v37.fasta --o ../outputr/

target		: ../0247401_D_BED_20090724_hg19_MERGED.bed

test		: ../P0667N_GATKrealigned_duplicates_marked.bam

control		: ../P0667T_GATKrealigned_duplicates_marked.bam

outfolder	: ../outputr/

numBin		: [20]

minreaddepth	: 10

minNBases	: 10

sam		: False

pval		: 0.05

sampleName	: No-SampleName

nomultimapped	: False

plot		: False

bedInput		: False

minExon		: 2000

largeDeletion	: False

removeDups	: False

Creating Output Folder :  Done.

Traceback (most recent call last):

  File "contra.py", line 625, in <module>

    main()

  File "contra.py", line 570, in main

    get_genome(params.TEST, genomeFile)

  File "/panfs/roc/groups/8/umgc-staff/abrah023/AndyTemp/CONTRA.v2.0.8/scripts/get_chr_length.py", line 31, in get_genome

    raw_header = subprocess.Popen(args, stdout = subprocess.PIPE).communicate()[0]

  File "/home/umgc-staff/abrah023/bin/miniconda3/envs/contra/lib/python2.6/subprocess.py", line 623, in __init__

    errread, errwrite)

  File "/home/umgc-staff/abrah023/bin/miniconda3/envs/contra/lib/python2.6/subprocess.py", line 1141, in _execute_child

    raise child_exception

OSError: [Errno 2] No such file or directory

```

## Exome data

#### from: Andrew 6/14/19

You should now have access to nelsona2, where the somatic DNA exome data is located.  Rebecca and Christy have done the primary work on these samples, so please reach out to them if you have questions about the exome data.  Also, there are directories on there of sequencing from the Illumina TST170 panel, a focused DNAseq panel that has copy number calling built into the stock pipeline (using an algorithm called Craft).

Tim has cross walk files; as you will find out there are multiple different sample identifiers for each surgical specimen.

#### from: Christy re coverage data 7/10/19

Just realized I didn't send you the final coverage data. My apologies.
The data is now here: `/home/nelsona2/shared/ovarian_Jan2019/DNA_project/coverage`
There are 3 excel files with coverage as listed below. (There is also a README.txt in the above directory with the same information.) Let me know if you have any questions!
Best,
Christy

OvCA_exome_capture_coverage.xlsx
Coverage by chromosome and exon for the bed file provided by Agilent for the capture (S07604715)


OvCA_exome_exon_flattened_coverage.xlsx
Coverage by chromosome, gene and exon using a bed file created by using the S07604715 capture's target gene names to pull the full exon-level coordinates from UCSC (for RefSeq gene names, Ensembl gene names, miRNAs and other non-coding genes). The purpose of this is to make sure each gene is fully covered by the capture, i.e. to help identify any exons that were left out of the capture bed file because they were too difficult to sequence or didn't perform well, or just by accident. (Based on our clinical experience, this happens more than you might think.) Going to this extra effort to pull the full exon bed files from another source allows us to see when exons have been missed by the capture. For each gene, any overlapping exons were merged so that an individual base within in a gene is only counted once for coverage, and overlapping exons are counted/listed in the spreadsheet as a single "meta-exon".

OvCA_exome_fullreduce_coverage.xlsx
Coverage by chromosome and exon. Same bed file as in OvCA_exome_exon_flattened_coverage.xlsx, however instead of only merging overlapping exons if they occurred w any overlapping exons were merged with each other, regardless of gene. This gives us a bed file with any base in the capture only counted once for coverage
 purposes, even if it is included in multiple exons in the same or different genes.

## CNV w/ scRNA @Tirosh2016

This paper is the only other case Tim is aware of where a group was able to effectively show CNV in single cell expression data.

* This group took human oligodendrogliomas and isolated ~4300 cells for sequencing.
* They constructed a developmental program from genome-wide expression signatures.
* The analysis produced the conclusion that these cells display 2 distinct developmental programs.
* Subclonal point mutation and insitu hybridization was also done as verification of these retults.

#### CNV Method

* Their CNV approach was to define a window along a chromosomal mapping. By doing this, they effectivley created "bins" of expression level to define relative changes in expression.
* They identified two cell types that aligned with a genetic character (high values at 1p and 19q) which they defined as baseline expression.
* This was used to define the baseline for microglia and oligdendrocytes.
* PCA comprised the main statistical approach.

## Comparing CNV tools @Zare2017

This paper explored a comparative analysis between current CNV analysis tools that operate in the context of whole exome sequencing which in wide use in the field. The group narrowed the landscape down to just 5 tools that meet a few criteria.

* There are 3 approaches to identifying CNVs
    + read count (read depth)
    + paired-end
    + assembly
* All tools the group evaluated used the read depth method since the pair-end and assembly methods are rendered ineffective with low read coverage like is seen in exome data. All CNV detection tools for WES are based on this method as a result.
* Ambiguities in alignment can create bias in the RD approach.
* The hybridization process and an uneven distribution of reads in exonic regions leads to bias.
* There are reads in the WES data that will be overlapping noise which would otherwise be delineated in the scRNA data. I will have to account for this.
* As of 2016, there are 15 seq-based CNV tools.
* B allele frequencies (BAF) is used to address tumor complexity in some of these tools.
* Group used both read and synthesized data.
* Look at table 1 for feature breakdown
* Look at table 4 for performance summary

#### ADTEx

* Newest of the tools they evaluated
* Has ability to leverage BAF
* Uses Discrete Wavelet Transform as a preprocessing step to reduce noise.
* Two Hidden Markov Models are used in detection.
* CBS is used in segmentation

#### Contra

* used for very small target regions.
* normalizes read count and log ratios for each base.
* better for reducing effect of GC bias.
* addresses problem of very low coverage and GC bias.

#### cn.MOPS

* Can use multiple samples for each genomics region to create a better estimate
* Uses a non-overlapping sliding window.
* Creates a null-hypothesis to measure distance to observed value.
* Can reduce false discovery rate

#### ExomeCNV

* Specifically design for WES data.
* Can use BAF data
* Counts overlapping reads from exons by using these counts for tumor and normal.
* Can also detect loss of heterzygosity.

#### VarScan2

* Also specifically designed for WES data from tumor-normal.
* Does not use a sliding window.
* Calculates tumor to normal read count ratios of high quality base that fulfill minimum coverage requirements.
* Using Fischers test, consecutive bases do not change significantly are binned together.
* Does not utilize a segmentation algorithm, CBS is advised.

#### Results

* The tools show low consistency.
* only about 25% of the true amplified genes and deleted genes were identified by all tools in the gene-based comparison.
* In the segment-based comparison, the sensitivities and FDRs were all comparably similar to the gene-based comparison.
* There was no consistency among tools for the size and number of detected CNVs as well.
* Due to contra's approach, it excels with clean data but may not be suitable for messy cancer data.
* Mis-detection of poor coverage sequences is a central cause of the poor performance.
* Because of the poor performance across the tools, there is a great need for improvement in preprocessing techniques.
* A point made that may hold relevance to my project is that tumor subclonality has not been addressed by any tool. The granularity offered by our scRNA data could help with this.

#### Other tools

* varsimlab to generate synthetic cnv
* cghmcr to identify cnv genes using refseq gene id
* genomicranges to detect overlapping regions

## Jason's Work


Jason sent me his working directory for the early phase of the CNV project. It is located at

* `/starr_lab/ocpmi/methods/jason_cnv`

#### from: Jason 6/15/19

I have previously explored large scale CNV using the single cell data. I’ve attached my directory of scripts and figures. Please go ahead and use whatever you can from them. The coding might be a little messy… not exactly plug-n-chug, but you should be able to get some use out of it.

As you may know, the single cell data isn’t really fit for gene-level CNV analysis because only 10-15% of the gene space is covered. So my approach was to look at the average expression level of all genes measured in each chromosome arm, for each cell. I scaled these average values across all the cells (vertically in the figures) that we had annotated as non-epithelial cells. The heatmaps show chromosome arms across the X axis and individual cells across the Y axis. So, rather than looking for CNV in a gene, I’m looking for entire chromosome arm amplifications & deletions.

One useful file will be “ENSEMBLgenes.csv” which indicates the chromosome number and location of each gene. Also, in the CNV.Rmd notebook I have hardcoded the centromere position of each chromosome. Together these will allow you to explore average gene expression by chromosome arm.

Please note that if you are using the most recent patient data from Tim, there will be more cells in each patient because we re-ran the Cell Ranger pipeline since I did this analysis. We have also updated the cell type annotation for each cell since I’ve done this.

The vertical colored bar on the left of the heatmaps show the cell type. They are colored according to “Picture1.png”. On the right side of the heatmaps in small font you will see the cluster number and the annotated cell type according to our outdated Seurat pipeline.

If you have any question or would like to discuss in more detail, I’ll be happy to connect with you sometime this week to have a look together. I live in Colorado so we would use Skype or Google Hangouts if you’d like to do this.


# Awesome single cell repo

I found a really comprehensive list of single cell analysis tools at the github below.

* https://github.com/seandavi/awesome-single-cell

# CCGD Upgrade

#### Project doc location

* `/home/chris/starr_lab/ccgd/refs/CCGD Project.docx`


***

# References
